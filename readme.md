# 实验背景
考虑4个任务：任务A和任务B比较长，任务C和任务D比较短。任务A和任务B有比较强的内存相关性即他们要么代码段有很多重合的地方，要么数据有很多重合的地方。同样的，任务C和任务D也有比较强的内存相关性。但是任务A和任务C几乎没有内存相关性，任务B和D也没有内存相关性。现在有两个CPU核心。如果把任务A和任务C调度到核心1上，任务C和任务D调度到核心2上，那么负载是均衡的。不过，这样的调度方案对cache未必是友好的。每个CPU核心都有一个私有的L1 cache。由于任务A和任务C没有内存相关性，任务A执行的时候，会把任务C的缓存替换出去。同样，任务C执行的时候，也会把任务A的缓存替换出去。这样会大大提高cache_miss。降低CPU性能。把任务A和任务B放到一个核心上，虽然会导致负载不均衡，使得任务A和任务B的核心需要花费更多的时间去完成任务，而另一个核心在完成任务后进入空闲状态。但是这种调度方法对cache是友好的。原因是：第一，Linux的CFS调度让任务A和任务B几乎按相同的进度进行。第二，任务A加载的缓存，任务B可以复用。这样能降低cache_miss,从而提高性能。这就导致了一个需要权衡的点，到底应该优先考虑负载均衡把任务A和B放在不同的核心上，还是优先考虑cache，把任务A和B放到同一个核心上？
# 实验目的
证明把任务A和任务B放到同一个核心上运行，对cache更友好。
# 实验设计
## 任务设计
4个任务都运行矩阵乘法。任务A和任务B对矩阵1(1000x1000,double类型)和矩阵2(1000x1000,double类型)进行乘法运算。重复计算20次。任务C和任务D对矩阵3(1000x1000,double类型）和矩阵4（1000x1000,double类型）进行乘法 运算。重复10次。
为了更好地体现内存相关性，这里的矩阵乘法不存储结果。矩阵元素相乘的结果全部累加到一个变量中 。这样使得任务A和任务B几乎没有私有的内存空间。从而使实验效果更加明显。
## 实验安排
**第一组实验：负载不均衡**
把任务A和任务B放到cpu 0中。把任务C和任务D放到cpu 2中。
**第二组实验：负载均衡**
把任务A和任务C放到cpu 0中。把任务B和任务D放到cpu 2中。

## 实验工具
本实验使用perf工具监控任务的cache_misses。发生cache_misses时，相应的硬件计数器就加1。perf在进程开始的时候检查一次硬件计数器，记录开始时的cache_misses次数。在进程结束后检查一次硬件计数器，记录此时的cache_misses次数。两个数据相减就是这个进程生命周期发生的cache_misses。
